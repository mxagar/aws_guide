{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AWS S3 Interaction Examples with Boto3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains interaction examples with AWS S3 using `boto3`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authentication\n",
    "\n",
    "For authentication, we have several options:\n",
    "\n",
    "1. Save temporary credentials as environment variables, for instance in `.env`.\n",
    "2. Save temporary credentials in `~/.aws/credentials`.\n",
    "\n",
    "Example `~/.aws/credentials`:\n",
    "\n",
    "```\n",
    "[myprofile]\n",
    "aws_access_key_id = your_AWS_ACCESS_KEY_ID\n",
    "aws_secret_access_key = your_AWS_SECRET_ACCESS_KEY\n",
    "aws_session_token = your_AWS_SESSION_TOKEN\n",
    "aws_default_region = your_AWS_DEFAULT_REGION\n",
    "```\n",
    "\n",
    "In our code, we can authenticate as follows, depending on the case:\n",
    "\n",
    "```python\n",
    "# 1. Enviornment variables:\n",
    "# ... \n",
    "load_dotenv()\n",
    "s3_client = boto3.client('s3')\n",
    "\n",
    "# 2. ~/.aws/credentials:\n",
    "# ...\n",
    "session = boto3.Session(profile_name='myprofile')\n",
    "s3_client = session.client('s3')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Interaction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Create S3 client\n",
    "- Create/Delete S3 Buckets\n",
    "- Upload/Download/Delete File to/from S3 Bucket\n",
    "- List Files + Download Selected Files from DBBGL S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "from typing import Optional\n",
    "\n",
    "from tqdm import tqdm\n",
    "import boto3\n",
    "import botocore\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "AWS_ACCESS_KEY_ID = os.getenv(\"AWS_ACCESS_KEY_ID\")\n",
    "AWS_SECRET_ACCESS_KEY = os.getenv(\"AWS_SECRET_ACCESS_KEY\")\n",
    "AWS_SESSION_TOKEN = os.getenv(\"AWS_SESSION_TOKEN\")\n",
    "AWS_DEFAULT_REGION = os.getenv(\"AWS_DEFAULT_REGION\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# S3 client: we interact with it (in global scope) in all functions!\n",
    "s3_client = boto3.client('s3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_s3_client() -> boto3.client:\n",
    "    \"\"\"Create an S3 client.\"\"\"\n",
    "    # Get credentials from .env file\n",
    "    load_dotenv()\n",
    "    AWS_ACCESS_KEY_ID = os.getenv(\"AWS_ACCESS_KEY_ID\", default=None)\n",
    "    AWS_SECRET_ACCESS_KEY = os.getenv(\"AWS_SECRET_ACCESS_KEY\", default=None)\n",
    "    AWS_SESSION_TOKEN = os.getenv(\"AWS_SESSION_TOKEN\", default=None)\n",
    "    AWS_DEFAULT_REGION = os.getenv(\"AWS_DEFAULT_REGION\", default=None)\n",
    "    if AWS_ACCESS_KEY_ID is None \\\n",
    "        or AWS_SECRET_ACCESS_KEY is None \\\n",
    "        or AWS_SESSION_TOKEN is None \\\n",
    "        or AWS_DEFAULT_REGION is None:\n",
    "        raise ValueError(\"Missing AWS credentials in .env file\")\n",
    "    \n",
    "    # Create S3 client\n",
    "    s3_client = boto3.client(\n",
    "        's3',\n",
    "        aws_access_key_id=AWS_ACCESS_KEY_ID,\n",
    "        aws_secret_access_key=AWS_SECRET_ACCESS_KEY,\n",
    "        aws_session_token=AWS_SESSION_TOKEN,\n",
    "        region_name=AWS_DEFAULT_REGION\n",
    "    )\n",
    "\n",
    "    return s3_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_client = create_s3_client()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create/Delete S3 Buckets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_buckets(s3_client: Optional[boto3.client] = None) -> None:\n",
    "    if s3_client is None:\n",
    "        s3_client = create_s3_client()\n",
    "    buckets = s3_client.list_buckets()\n",
    "    print(\"Available Buckets:\")\n",
    "    for bucket in buckets[\"Buckets\"]:\n",
    "        print(f\"  - {bucket['Name']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_buckets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_s3_bucket(bucket_name: str,\n",
    "                     s3_client: Optional[boto3.client] = None) -> None:\n",
    "    if s3_client is None:\n",
    "        s3_client = create_s3_client()\n",
    "    region = s3_client.meta.region_name\n",
    "\n",
    "    try:\n",
    "        response = s3_client.create_bucket(\n",
    "            Bucket=bucket_name,\n",
    "            CreateBucketConfiguration={\n",
    "                'LocationConstraint': region\n",
    "            }\n",
    "        )\n",
    "        print(f\"Bucket {bucket_name} created successfully in region {region}.\")\n",
    "    except botocore.exceptions.ClientError as e:\n",
    "        print(f\"Error: {e.response['Error']['Message']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_s3_bucket(bucket_name = \"test-dummy-dataset-repo-2024\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_buckets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_s3_bucket(bucket_name: str, s3_client: Optional[boto3.client] = None) -> None:\n",
    "    if s3_client is None:\n",
    "        s3_client = create_s3_client()\n",
    "\n",
    "    try:\n",
    "        response = s3_client.delete_bucket(Bucket=bucket_name)\n",
    "        print(f\"Bucket {bucket_name} deleted successfully.\")\n",
    "    except botocore.exceptions.ClientError as e:\n",
    "        print(f\"Error: {e.response['Error']['Message']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delete_s3_bucket(bucket_name = \"test-dummy-dataset-repo-2024\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_buckets()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload/Download/Delete File to/from S3 Bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_file_from_s3(bucket_name: str,\n",
    "                          object_name: str,\n",
    "                          file_name: Optional[str] = None,\n",
    "                          s3_client: Optional[boto3.client] = None) -> None:\n",
    "    if s3_client is None:\n",
    "        s3_client = create_s3_client()\n",
    "    if file_name is None:\n",
    "        file_name = object_name\n",
    "\n",
    "    # Ensure all directories in the file path are created\n",
    "    if \"/\" in file_name:\n",
    "        Path(file_name).parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    try:\n",
    "        s3_client.download_file(bucket_name, object_name, file_name)\n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading file: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_file_to_s3(bucket_name: str,\n",
    "                      file_name: str,\n",
    "                      object_name: Optional[str] = None,\n",
    "                      s3_client: Optional[boto3.client] = None) -> None:\n",
    "    if s3_client is None:\n",
    "        s3_client = create_s3_client()\n",
    "    if object_name is None:\n",
    "        object_name = file_name\n",
    "\n",
    "    try:\n",
    "        s3_client.upload_file(file_name, bucket_name, object_name)\n",
    "    except Exception as e:\n",
    "        print(f\"Error uploading file: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_file_from_s3(bucket_name: str,\n",
    "                        object_name: str,\n",
    "                        s3_client: Optional[boto3.client] = None) -> None:\n",
    "    if s3_client is None:\n",
    "        s3_client = create_s3_client()\n",
    "\n",
    "    try:\n",
    "        s3_client.delete_object(Bucket=bucket_name, Key=object_name)\n",
    "    except Exception as e:\n",
    "        print(f\"Error deleting file: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_buckets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upload_file_to_s3(\"test-dummy-dataset-repo-2025\", \"my_folder/my_image.JPG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_file_from_s3(\"test-dummy-dataset-repo-2025\", \"my_folder/my_image.JPG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delete_file_from_s3(\"test-dummy-dataset-repo-2025\", \"my_folder/my_image.JPG\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List Files + Download Selected Files from DBBGL S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_entries_in_bucket(bucket_name: str,\n",
    "                               s3_client: Optional[boto3.client] = None) -> list:\n",
    "    if s3_client is None:\n",
    "        s3_client = create_s3_client()\n",
    "    file_entries = []\n",
    "\n",
    "    try:\n",
    "        paginator = s3_client.get_paginator('list_objects_v2')\n",
    "        for page in tqdm(paginator.paginate(Bucket=bucket_name), desc=\"Retrieving files from bucket\", unit=\"page\"):\n",
    "            if 'Contents' in page:\n",
    "                file_entries.extend(page['Contents'])\n",
    "        print(f\"Total files found: {len(file_entries)}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "    \n",
    "    return file_entries\n",
    "\n",
    "\n",
    "def print_filenames_in_bucket(bucket_name: str, s3_client: Optional[boto3.client] = None) -> None:\n",
    "    file_entries = get_file_entries_in_bucket(bucket_name, s3_client=s3_client)\n",
    "    if len(file_entries) > 0:\n",
    "        for file in file_entries:\n",
    "            print(file['Key'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_entries = get_file_entries_in_bucket(\"test-dummy-dataset-repo-2025\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(file_entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_entries[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def organize_file_entries_into_dataframe(file_entries: list) -> pd.DataFrame:\n",
    "    data = []\n",
    "    for entry in file_entries:\n",
    "        token, filename = entry['Key'].split('/', 1)\n",
    "        modified = entry['LastModified']\n",
    "        size = entry['Size']\n",
    "        data.append({'token': token, 'filename': filename, 'las_modified': modified, 'size': size})\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = organize_file_entries_into_dataframe(file_entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file_path = \"s3_file_entries.csv\"\n",
    "df.to_csv(csv_file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file_path = \"s3_file_entries.csv\"\n",
    "df = pd.read_csv(csv_file_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
